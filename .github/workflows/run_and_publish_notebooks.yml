# =============================================================================
# Run Notebooks & Publish to GitHub Pages
# =============================================================================
# This workflow:
#   1. Detects new or modified Jupyter notebooks
#   2. Executes them in a Neurodesk container to validate they run correctly
#   3. Builds the Jupyter Book and publishes to GitHub Pages
#
# Triggers:
#   - Push to main (when notebooks or book markdown files change)
#   - Pull requests to main (for validation, no deployment)
#   - Manual dispatch (with options for image override, force execution, etc.)
# =============================================================================

name: Run Notebooks & Publish

defaults:
  run:
    shell: bash

# =============================================================================
# TRIGGERS
# =============================================================================
on:
  push:
    branches: [main]
    paths:
      - '**/*.ipynb'
      - 'books/**/*.md'

  pull_request:
    branches: [main]
    paths:
      - '**/*.ipynb'
      - 'books/**/*.md'
    types: [opened, synchronize, reopened, ready_for_review]

  workflow_dispatch:
    inputs:
      image_override:
        description: 'Override the Docker image (e.g. ghcr.io/neurodesk/neurodesktop/neurodesktop:2024-01-01)'
        required: false
        type: string
      force_execution:
        description: 'Force execution of all notebooks'
        required: false
        type: boolean
        default: false
      force_deploy_pages:
        description: 'Force deploy pages'
        required: false
        type: boolean
        default: false
      notebook_selector:
        description: 'Path relative to books/ (e.g. examples/workflows/nipype_short.ipynb)'
        required: false
        type: string
      use_self_hosted:
        description: 'Use self-hosted runner (check for self-hosted, default: GitHub-hosted)'
        required: false
        type: boolean
        default: false

# =============================================================================
# CONCURRENCY
# =============================================================================
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: false

# =============================================================================
# JOBS
# =============================================================================
jobs:

  # ---------------------------------------------------------------------------
  # SETUP: Determine runner and Neurodesk image
  # ---------------------------------------------------------------------------
  setup:
    name: Setup Environment
    runs-on: ubuntu-22.04
    outputs:
      runner: ${{ steps.select_runner.outputs.runner }}
      neurodesk_image: ${{ steps.get_image.outputs.neurodesk_image }}

    steps:
      - uses: actions/checkout@34e114876b0b11c390a56381ad16ebd13914f8d5

      - name: Select runner
        id: select_runner
        run: |
          # For workflow_dispatch, use the use_self_hosted input
          if [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
            if [ "${{ inputs.use_self_hosted }}" = "true" ]; then
              echo "runner=self-hosted" >> $GITHUB_OUTPUT
            else
              echo "runner=ubuntu-22.04" >> $GITHUB_OUTPUT
            fi
          # For push/PR, use self-hosted for main repo, ubuntu for forks
          elif [ "${{ github.repository }}" = "neurodesk/neurodeskedu" ]; then
            echo "runner=self-hosted" >> $GITHUB_OUTPUT
          else
            echo "runner=ubuntu-22.04" >> $GITHUB_OUTPUT
          fi

      - name: Determine Neurodesk image version
        id: get_image
        run: |
          if [ -n "${{ inputs.image_override }}" ]; then
            echo "neurodesk_image=${{ inputs.image_override }}" >> $GITHUB_OUTPUT
          else
            curl -s https://raw.githubusercontent.com/neurodesk/neurodesk.github.io/main/data/neurodesktop.toml -o neurodesktop.toml
            VERSION=$(grep 'jupyter_neurodesk_version = ' neurodesktop.toml | cut -d '"' -f 2)
            echo "neurodesk_image=ghcr.io/neurodesk/neurodesktop/neurodesktop:$VERSION" >> $GITHUB_OUTPUT
          fi

      - name: Cache Docker image
        id: docker-cache
        uses: actions/cache@v5.0.1
        with:
          path: ~/docker-image-cache
          key: docker-neurodesk-${{ steps.get_image.outputs.neurodesk_image }}

      - name: Prefetch Docker image
        if: steps.docker-cache.outputs.cache-hit != 'true'
        run: |
          IMAGE="${{ steps.get_image.outputs.neurodesk_image }}"
          CACHE_FILE=~/docker-image-cache/neurodesk.tar
          mkdir -p ~/docker-image-cache
          
          echo "Cache miss. Pulling $IMAGE..."
          docker pull "$IMAGE"
          
          echo "Saving image to cache..."
          docker save -o "$CACHE_FILE" "$IMAGE"

      # --- CVMFS Cache Warmer ---
      - name: Cache CVMFS apt packages
        uses: actions/cache@v5.0.1
        with:
          path: ${{ github.workspace }}/.cache/cvmfs-apt
          key: cvmfs-apt-${{ runner.os }}-v1

      - name: Setup CVMFS (Warm Cache)
        uses: cvmfs-contrib/github-action-cvmfs@v5.3
        with:
          cvmfs_repositories: neurodesk.ardc.edu.au
          cvmfs_http_proxy: DIRECT
          cvmfs_quota_limit: 5000
          apt_cache: ${{ github.workspace }}/.cache/cvmfs-apt

      # --- Pip Cache Warmer ---
      - name: Cache Conda/Python dependencies
        uses: actions/cache@v5.0.1
        with:
          path: ${{ github.workspace }}/.cache/pip
          key: pip-book-${{ hashFiles('books/_config.yml') }}

      - name: Install Dependencies (Warm Cache)
        env:
          PIP_CACHE_DIR: ${{ github.workspace }}/.cache/pip
        run: |
          mkdir -p ${{ github.workspace }}/.cache/pip
          pip install "jupyter-book<2.0.0" ghp-import

  # ---------------------------------------------------------------------------
  # SELECT NOTEBOOKS: Determine which notebooks to run (changed or manually selected)
  # ---------------------------------------------------------------------------
  select-notebooks:
    name: Select Notebooks to Run
    runs-on: ubuntu-22.04
    outputs:
      notebook_list: ${{ steps.list_notebooks.outputs.notebook_list }}

    steps:
      - uses: actions/checkout@34e114876b0b11c390a56381ad16ebd13914f8d5

      - name: Find changed notebook files
        id: find_changed
        uses: tj-actions/changed-files@c3a1bb2c992d77180ae65be6ae6c166cf40f857c
        with:
          path: "./books"
          files: |
            **/*.ipynb
          dir_names_exclude_current_dir: "true"

      - name: Build notebook list for matrix
        id: list_notebooks
        run: |
          # Determine which notebooks to run based on trigger type
          if [ "${{ inputs.force_execution }}" == "true" ]; then
            echo "Mode: Force execution of ALL notebooks"
            changed_notebooks=$(find books -name "*.ipynb" | sed 's|^books/||')

          elif [ -n "${{ inputs.notebook_selector }}" ]; then
            echo "Mode: Running specific notebook: ${{ inputs.notebook_selector }}"
            changed_notebooks="${{ inputs.notebook_selector }}"

          else
            echo "Mode: Running changed notebooks only"
            echo "Changed files: ${{ steps.find_changed.outputs.all_changed_files }}"
            changed_notebooks=$(echo "${{ steps.find_changed.outputs.all_changed_files }}")
          fi

          # Build JSON array for matrix strategy
          notebook_list='['
          for NOTEBOOK in $(echo "${changed_notebooks}"); do
            notebook_list+="\"${NOTEBOOK}\","
          done
          notebook_list=$(sed '$s/,$//' <<< $notebook_list)
          notebook_list+=']'

          echo "notebook_list=${notebook_list}"
          echo "notebook_list=${notebook_list}" >> $GITHUB_OUTPUT

  # ---------------------------------------------------------------------------
  # RUN NOTEBOOKS: Execute each changed notebook in Neurodesk container
  # ---------------------------------------------------------------------------
  run-notebooks:
    name: Run Notebook
    needs: [setup, select-notebooks]
    if: ${{ needs.select-notebooks.outputs.notebook_list != '[]' }}
    runs-on: ${{ needs.setup.outputs.runner }}
    timeout-minutes: 1500

    strategy:
      fail-fast: false
      matrix:
        notebooks: ${{ fromJson(needs.select-notebooks.outputs.notebook_list) }}

    steps:
      - uses: actions/checkout@34e114876b0b11c390a56381ad16ebd13914f8d5

      - name: Set notebook environment variables
        run: echo "NOTEBOOK=$(basename -s .ipynb ${{ matrix.notebooks }})" >> $GITHUB_ENV

      - name: Configure runner (Optimize Disk Space)
        if: runner.os == 'Linux'
        run: |
          if [ "${{ needs.setup.outputs.runner }}" != "self-hosted" ]; then
             echo "Optimizing GitHub-hosted runner..."
             sudo swapoff -a && sudo rm -rf /mnt/*
             BASE_PATH=/mnt
          else
             echo "Configuring self-hosted runner..."
             # Be careful not to wipe /mnt on self-hosted if it's used
             BASE_PATH=/storage
          fi
          
          echo "Using BASE_PATH=$BASE_PATH"
          echo "BASE_PATH=$BASE_PATH" >> $GITHUB_ENV
          
          # Setup directories
          sudo mkdir -p $BASE_PATH/tmp
          sudo chown $USER $BASE_PATH/tmp
          sudo mkdir -p $BASE_PATH/docker
          
          # Configure Docker to use new data-root
          echo "{\"data-root\": \"$BASE_PATH/docker\"}" | sudo tee /etc/docker/daemon.json
          sudo systemctl restart docker
          
          # Clean up existing space
          docker system prune -af || true

      # -------------------------------------------------------------------------
      # CVMFS Setup (for GitHub-hosted runners)
      # -------------------------------------------------------------------------
      - name: Cache CVMFS apt packages
        uses: actions/cache@v5.0.1
        id: cvmfs-cache
        with:
          path: ${{ github.workspace }}/.cache/cvmfs-apt
          key: cvmfs-apt-${{ runner.os }}-v1

      - name: Create Neurodesk CVMFS public key
        run: |
          sudo mkdir -p /etc/cvmfs/keys/ardc.edu.au
          sudo tee /etc/cvmfs/keys/ardc.edu.au/neurodesk.ardc.edu.au.pub << 'EOF'
          -----BEGIN PUBLIC KEY-----
          MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAwUPEmxDp217SAtZxaBep
          Bi2TQcLoh5AJ//HSIz68ypjOGFjwExGlHb95Frhu1SpcH5OASbV+jJ60oEBLi3sD
          qA6rGYt9kVi90lWvEjQnhBkPb0uWcp1gNqQAUocybCzHvoiG3fUzAe259CrK09qR
          pX8sZhgK3eHlfx4ycyMiIQeg66AHlgVCJ2fKa6fl1vnh6adJEPULmn6vZnevvUke
          I6U1VcYTKm5dPMrOlY/fGimKlyWvivzVv1laa5TAR2Dt4CfdQncOz+rkXmWjLjkD
          87WMiTgtKybsmMLb2yCGSgLSArlSWhbMA0MaZSzAwE9PJKCCMvTANo5644zc8jBe
          NQIDAQAB
          -----END PUBLIC KEY-----
          EOF

      - name: Setup CVMFS
        uses: cvmfs-contrib/github-action-cvmfs@v5.3
        with:
          cvmfs_repositories: neurodesk.ardc.edu.au
          cvmfs_http_proxy: DIRECT
          cvmfs_quota_limit: 5000
          cvmfs_keys_dir: /etc/cvmfs/keys/ardc.edu.au
          cvmfs_server_url: "http://cvmfs-geoproximity.neurodesk.org/cvmfs/@fqrn@;http://cvmfs.neurodesk.org/cvmfs/@fqrn@;http://s1osggoc-cvmfs.openhtc.io:8080/cvmfs/@fqrn@;http://s1fnal-cvmfs.openhtc.io:8080/cvmfs/@fqrn@;http://s1sampa-cvmfs.openhtc.io:8080/cvmfs/@fqrn@;http://s1brisbane-cvmfs.openhtc.io/cvmfs/@fqrn@;http://s1nikhef-cvmfs.openhtc.io/cvmfs/@fqrn@;http://s1bnl-cvmfs.openhtc.io/cvmfs/@fqrn@;http://s1perth-cvmfs.openhtc.io/cvmfs/@fqrn@"
          apt_cache: ${{ github.workspace }}/.cache/cvmfs-apt

      - name: Debug CVMFS Configuration
        run: |
          echo "========== CVMFS CONFIG DEBUG =========="
          
          echo "=== CVMFS version ==="
          cvmfs2 --version || echo "cvmfs2 not found"
          
          echo ""
          echo "=== /etc/cvmfs/default.local ==="
          cat /etc/cvmfs/default.local 2>/dev/null || echo "File not found"
          
          echo ""
          echo "=== /etc/cvmfs/default.d/ contents ==="
          ls -la /etc/cvmfs/default.d/ 2>/dev/null || echo "Directory not found"
          cat /etc/cvmfs/default.d/*.conf 2>/dev/null || echo "No conf files"
          
          echo ""
          echo "=== /etc/cvmfs/config.d/ contents ==="
          ls -la /etc/cvmfs/config.d/ 2>/dev/null || echo "Directory not found"
          
          echo ""
          echo "=== neurodesk.ardc.edu.au.conf ==="
          cat /etc/cvmfs/config.d/neurodesk.ardc.edu.au.conf 2>/dev/null || echo "File not found"
          
          echo ""
          echo "=== /etc/cvmfs/keys/ contents ==="
          ls -laR /etc/cvmfs/keys/ 2>/dev/null || echo "Directory not found"
          
          echo ""
          echo "=== Public key file ==="
          cat /etc/cvmfs/keys/neurodesk.ardc.edu.au.pub 2>/dev/null || \
          cat /etc/cvmfs/keys/ardc.edu.au/neurodesk.ardc.edu.au.pub 2>/dev/null || \
          echo "Public key file not found"
          
          echo ""
          echo "=== cvmfs_config chksetup ==="
          sudo cvmfs_config chksetup || echo "chksetup failed"
          
          echo "========================================="

      - name: Probe and Mount CVMFS
        run: |
          echo "========== CVMFS MOUNT =========="
          
          echo "=== Trying cvmfs_config probe ==="
          sudo cvmfs_config probe neurodesk.ardc.edu.au || echo "Probe failed"
          
          echo ""
          echo "=== Check autofs status ==="
          sudo systemctl status autofs || echo "autofs status check failed"
          
          echo ""
          echo "=== Trigger autofs mount by accessing path ==="
          ls /cvmfs/neurodesk.ardc.edu.au 2>&1 || echo "Direct access failed"
          
          echo ""
          echo "=== Current mounts ==="
          mount | grep cvmfs || echo "No cvmfs mounts found"
          
          echo ""
          echo "=== Try manual mount if autofs failed ==="
          if [ ! -d "/cvmfs/neurodesk.ardc.edu.au" ] || [ -z "$(ls -A /cvmfs/neurodesk.ardc.edu.au 2>/dev/null)" ]; then
            echo "Attempting manual mount..."
            sudo mkdir -p /cvmfs/neurodesk.ardc.edu.au
            sudo mount -t cvmfs neurodesk.ardc.edu.au /cvmfs/neurodesk.ardc.edu.au || echo "Manual mount failed"
          fi
          
          echo ""
          echo "=== Final CVMFS status ==="
          cvmfs_config stat neurodesk.ardc.edu.au || echo "stat failed"
          
          echo ""
          echo "=== CVMFS contents ==="
          ls -la /cvmfs/neurodesk.ardc.edu.au/ | head -30 || echo "Still not accessible"
          
          echo "==================================="

      # -------------------------------------------------------------------------
      # Docker image caching
      # -------------------------------------------------------------------------
      - name: Cache Docker image
        uses: actions/cache@v5.0.1
        id: docker-cache
        with:
          path: ~/docker-image-cache
          key: docker-neurodesk-${{ needs.setup.outputs.neurodesk_image }}

      - name: Load Neurodesk image
        run: |
          IMAGE="${{ needs.setup.outputs.neurodesk_image }}"
          CACHE_FILE=~/docker-image-cache/neurodesk.tar
          
          if [ -f "$CACHE_FILE" ]; then
            echo "Loading image from cache..."
            docker load -i "$CACHE_FILE"
          else
            echo "Cache not found (unexpected). Pulling image..."
            docker pull "$IMAGE"
          fi
          
          echo "Image ready:"
          docker images "$IMAGE"

      - name: Debug environment in container
        run: |
          docker run --rm \
            -v /cvmfs:/cvmfs:ro \
            ${{ needs.setup.outputs.neurodesk_image }} \
            bash -c '
              echo "========== CONTAINER DEBUG INFO =========="
              
              echo "=== PATH ==="
              echo "$PATH"
              
              echo ""
              echo "=== CVMFS in container ==="
              ls -la /cvmfs/ 2>/dev/null || echo "ERROR: /cvmfs not accessible in container"
              ls -la /cvmfs/neurodesk.ardc.edu.au/ 2>/dev/null | head -20 || echo "ERROR: neurodesk.ardc.edu.au not accessible"
              
              echo ""
              echo "=== Module system init ==="
              if [ -f /usr/share/lmod/lmod/init/bash ]; then
                source /usr/share/lmod/lmod/init/bash
                echo "Lmod initialized successfully"
              else
                echo "ERROR: Lmod init script not found"
              fi
              
              echo ""
              echo "=== MODULEPATH ==="
              echo "$MODULEPATH"
              
              echo ""
              echo "=== Available modules (first 30) ==="
              module avail 2>&1 | head -30 || echo "ERROR: module avail failed"
              
              echo ""
              echo "=== Test: Load FSL module ==="
              module load fsl 2>&1 || echo "WARNING: Could not load fsl module"
              
              echo ""
              echo "=== Check FSL commands ==="
              which bet 2>/dev/null && echo "bet found: $(which bet)" || echo "WARNING: bet not found in PATH"
              which fsl 2>/dev/null && echo "fsl found: $(which fsl)" || echo "WARNING: fsl not found in PATH"
              
              echo ""
              echo "=== Updated PATH after module load ==="
              echo "$PATH"
              
              echo "==========================================="
            '

      # -------------------------------------------------------------------------
      # Docker execution with CVMFS mounted
      # -------------------------------------------------------------------------

      - name: Fix notebook kernelspec if needed
        run: |
          python3 << 'EOF'
          import json
          import sys

          notebook_path = "books/${{ matrix.notebooks }}"
          try:
              with open(notebook_path, 'r') as f:
                  notebook = json.load(f)

              # Fix conda-base-py or other problematic kernels
              if 'metadata' in notebook and 'kernelspec' in notebook['metadata']:
                  kernel_name = notebook['metadata']['kernelspec'].get('name', '')
                  if kernel_name == 'conda-base-py' or 'conda' in kernel_name:
                      print(f"Fixing kernelspec in {notebook_path}: {kernel_name} -> python3")
                      notebook['metadata']['kernelspec'] = {
                          "display_name": "Python 3",
                          "language": "python",
                          "name": "python3"
                      }
                      with open(notebook_path, 'w') as f:
                          json.dump(notebook, f, indent=1, ensure_ascii=False)
                          f.write('\n')
                  else:
                      print(f"Kernelspec OK: {kernel_name}")
          except Exception as e:
              print(f"Note: Could not process notebook (may not be ipynb): {e}")
          EOF

      - name: Execute notebook in Neurodesk container
        timeout-minutes: 1500
        env:
          GITHUB_PAT: ${{ secrets.GITHUB_TOKEN }}
        run: |
          echo "NOTEBOOK=$(basename -s .ipynb ${{ matrix.notebooks }})" >> $GITHUB_ENV
          echo "DIRNAME=$(dirname ${{ matrix.notebooks }})" >> $GITHUB_ENV

          docker run --rm \
            --shm-size=1gb \
            --privileged \
            --user=root \
            -v ${{ github.workspace }}:/home/jovyan/workspace \
            -v /cvmfs:/cvmfs:ro \
            -v ${{ env.BASE_PATH }}/tmp:/overlay-storage \
            -v ${{ github.workspace }}/.cache/pip:/home/jovyan/.cache/pip \
            -w /home/jovyan/workspace/books \
            -e NB_USER=jovyan \
            -e NB_UID="$(id -u)" \
            -e NB_GID="$(id -g)" \
            -e GITHUB_PAT="${GITHUB_PAT}" \
            -e BASH_ENV=/usr/share/lmod/lmod/init/bash \
            ${{ needs.setup.outputs.neurodesk_image }} \
            bash -c '
              set -e
              
              export PATH=/opt/conda/bin:$HOME/.local/bin:$PATH

              # Create apptainer overlay for modules that require it
              if [ ! -L /tmp/apptainer_overlay ]; then
                echo "Creating /tmp/apptainer_overlay symlink to /overlay-storage..."
                
                # Check if overlay exists in mounted storage
                if [ ! -f /overlay-storage/apptainer_overlay ]; then
                    echo "Creating 300MB overlay file on secondary disk..."
                    dd if=/dev/zero of=/overlay-storage/apptainer_overlay bs=1M count=300 status=none
                    mkfs.ext3 -F /overlay-storage/apptainer_overlay >/dev/null
                    chmod 777 /overlay-storage/apptainer_overlay
                fi
                
                # Symlink to expected location
                ln -sf /overlay-storage/apptainer_overlay /tmp/apptainer_overlay
              fi

              
              # Move apptainer working dir to secondary storage to save root disk space
              mkdir -p /overlay-storage/var_lib_apptainer
              chmod 777 /overlay-storage/var_lib_apptainer
              
              # Symlink /var/lib/apptainer if it doesn't exist or isn't a link yet
              if [ ! -L /var/lib/apptainer ]; then
                  rm -rf /var/lib/apptainer # Remove if it exists as a dir
                  ln -sf /overlay-storage/var_lib_apptainer /var/lib/apptainer
              fi

              # Initialize the module system
              if [ -f /usr/share/lmod/lmod/init/bash ]; then
                source /usr/share/lmod/lmod/init/bash
              elif [ -f /usr/share/module.sh ]; then
                source /usr/share/module.sh
              fi

              # Install dependencies (use pip --user to avoid /opt/conda permission issues)
              pip install --user "jupyter-book<2.0.0" ghp-import

              # Verify jupyter-book is available
              echo "Checking for jupyter-book..."
              which jupyter-book || echo "jupyter-book not found in PATH"

              # Verify CVMFS is accessible
              echo "Checking CVMFS mount..."
              ls -la /cvmfs/neurodesk.ardc.edu.au/ | head -10 || echo "CVMFS not accessible"

              # Execute the notebook
              jupyter-book build ${{ matrix.notebooks }}
            '

      - name: Print notebook output logs
        if: always()
        run: |
          echo "========== NOTEBOOK OUTPUT ==========="
          echo "PWD: $(pwd)"

          echo "=== Files in notebook source directory ==="
          ls -la books/$(dirname ${{ matrix.notebooks }}) || true

          echo "=== .nii.gz files in books ==="
          find books -name "*.nii.gz" -type f 2>/dev/null || echo "No .nii.gz files found"

          echo "=== Log files ==="
          for LOG in $(find "$GITHUB_WORKSPACE/books" -name "*.log" -type f 2>/dev/null); do
            echo "--- $LOG ---"
            cat "$LOG"
          done
          echo "========================================"

      - name: Check for execution errors
        run: |
          ERROR_LOG=$(find "$GITHUB_WORKSPACE/books" -name "*.err.log" -type f 2>/dev/null | head -1)
          if [ -n "$ERROR_LOG" ]; then
            echo "::error::Notebook execution failed!"
            exit 1
          fi

      - name: Upload notebook build logs
        if: always()
        uses: actions/upload-artifact@b7c566a772e6b6bfb58ed0dc250532a479d7789f
        with:
          name: notebook-logs-${{ env.NOTEBOOK }}
          path: |
            books/_build/**/reports/*.log
            books/_build/**/reports/*.err.log
            books/_build/**/.jupyter_cache/
          retention-days: 7
          if-no-files-found: ignore

  # ---------------------------------------------------------------------------
  # PUBLISH: Build complete book and deploy to GitHub Pages
  # ---------------------------------------------------------------------------
  publish-pages:
    name: Build & Publish to GitHub Pages
    needs: [run-notebooks, setup]
    if: ${{ always() && (needs.run-notebooks.result == 'success' || needs.run-notebooks.result == 'skipped') }}
    runs-on: ubuntu-22.04

    steps:
      - uses: actions/checkout@34e114876b0b11c390a56381ad16ebd13914f8d5

      - name: Configure runner (Optimize Disk Space)
        if: runner.os == 'Linux'
        run: |
          if [ "${{ needs.setup.outputs.runner }}" != "self-hosted" ]; then
             echo "Optimizing GitHub-hosted runner..."
             sudo swapoff -a && sudo rm -rf /mnt/*
             BASE_PATH=/mnt
          else
             echo "Configuring self-hosted runner..."
             # Be careful not to wipe /mnt on self-hosted if it's used
             BASE_PATH=/storage
          fi
          
          echo "Using BASE_PATH=$BASE_PATH"
          echo "BASE_PATH=$BASE_PATH" >> $GITHUB_ENV
          
          # Setup directories
          sudo mkdir -p $BASE_PATH/tmp
          sudo chown $USER $BASE_PATH/tmp
          sudo mkdir -p $BASE_PATH/docker
          
          # Configure Docker to use new data-root
          echo "{\"data-root\": \"$BASE_PATH/docker\"}" | sudo tee /etc/docker/daemon.json
          sudo systemctl restart docker
          
          # Clean up existing space
          docker system prune -af || true

      - name: Cache Docker image
        uses: actions/cache@v5.0.1
        with:
          path: ~/docker-image-cache
          key: docker-neurodesk-${{ needs.setup.outputs.neurodesk_image }}

      - name: Load Neurodesk image
        run: |
          IMAGE="${{ needs.setup.outputs.neurodesk_image }}"
          CACHE_FILE=~/docker-image-cache/neurodesk.tar
          if [ -f "$CACHE_FILE" ]; then
            echo "Loading image from cache..."
            docker load -i "$CACHE_FILE"
          else
            echo "::error::Docker image cache not found. This should not happen if run-notebooks succeeded."
            docker pull "$IMAGE"
          fi

      - name: Cache Conda/Python dependencies
        uses: actions/cache@v5.0.1
        with:
          path: ${{ github.workspace }}/.cache/pip
          key: pip-book-${{ hashFiles('books/_config.yml') }}
          restore-keys: |
            pip-book-

      - name: Build complete Jupyter Book (in Container)
        env:
          GITHUB_PAT: ${{ secrets.GITHUB_TOKEN }}
        run: |
          # Create cache dir if not exists
          mkdir -p ~/pip-cache

          docker run --rm \
            --user=root \
            -v ${{ github.workspace }}:/home/jovyan/workspace \
            -v ${{ github.workspace }}/.cache/pip:/home/jovyan/.cache/pip \
            -w /home/jovyan/workspace/books \
            -e GITHUB_PAT="${GITHUB_PAT}" \
            ${{ needs.setup.outputs.neurodesk_image }} \
            bash -c '
              set -e
              export PATH=/opt/conda/bin:$HOME/.local/bin:$PATH

              # Install dependencies
              # We use pip --user to take advantage of the mounted .cache/pip
              pip install --user r-irkernel ipykernel "jupyter-book<2.0.0" ghp-import

              # Generate table of contents
              /bin/bash ../.github/scripts/write-toc-entry.sh

              # Disable notebook execution (already executed in run-notebooks job)
              sed -i "s/execute_notebooks: .*/execute_notebooks: off/" _config.yml
              
              # Build the book
              jupyter-book build .
              
              # Fix permissions of generated files so host user can read them (if needed, though root usually fine on GHA)
              # But gh-pages action runs as runner user.
              chown -R 1001:1001 _build
            '

      - name: Deploy to GitHub Pages
        uses: peaceiris/actions-gh-pages@4f9cc6602d3f66b9c108549d475ec49e8ef4d45e
        if: github.ref == 'refs/heads/main' && github.event_name != 'pull_request'
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: ./books/_build/html
          keep_files: true
