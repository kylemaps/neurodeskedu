{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nextflow in Neurodesk: Minimal BIDS T1w QC\n",
    "####\n",
    "**Author:** Steffen Bollmann\n",
    "\n",
    "**Date:** 13 Feb 2026\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Citation and Resources\n",
    "#### Workflow engine\n",
    "- Di Tommaso, P., Chatzou, M., Floden, E. W., Barja, P. P., Palumbo, E., & Notredame, C. (2017). Nextflow enables reproducible computational workflows. *Nature Biotechnology, 35*(4), 316-319. https://doi.org/10.1038/nbt.3820\n",
    "\n",
    "#### Data access pattern used in this notebook\n",
    "- OpenNeuro (example dataset IDs can be cloned via DataLad): https://openneuro.org\n",
    "- Halchenko, Y. O., et al. (2021). DataLad: distributed system for joint management of code, data, and their relationship. *Journal of Open Source Software, 6*(63), 3262. https://doi.org/10.21105/joss.03262\n",
    "\n",
    "#### Platform\n",
    "- Neurodesk: https://www.neurodesk.org\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "1. [What this notebook builds](#What-this-notebook-builds)\n",
    "2. [Load Nextflow in Neurodesk](#Load-Nextflow-in-Neurodesk)\n",
    "3. [Write a DSL2 pipeline](#Write-a-DSL2-pipeline)\n",
    "4. [Create a tiny local BIDS dataset](#Create-a-tiny-local-BIDS-dataset)\n",
    "5. [Run Nextflow and inspect outputs](#Run-Nextflow-and-inspect-outputs)\n",
    "6. [Optional: OpenNeuro + DataLad helper script](#Optional:-OpenNeuro-+-DataLad-helper-script)\n",
    "7. [Dependencies and environment capture](#Dependencies-and-environment-capture)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What this notebook builds\n",
    "\n",
    "This notebook demonstrates a complete, beginner-friendly Nextflow workflow inside Neurodesk.\n",
    "\n",
    "The pipeline takes BIDS-style T1w MRI files and performs a simple quality-control pass per subject:\n",
    "- finds `*_T1w.nii` / `*_T1w.nii.gz` images in BIDS `anat/` folders,\n",
    "- runs one process per subject to extract shape and voxel size,\n",
    "- merges all per-subject tables into one summary TSV.\n",
    "\n",
    "To keep the notebook reliable for testing and teaching, the default run path uses a tiny synthetic BIDS dataset generated locally.\n",
    "\n",
    "An optional section also writes a DataLad/OpenNeuro helper script based on your requested pattern for real public data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Nextflow in Neurodesk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import importlib.util\n",
    "import os\n",
    "import shutil\n",
    "import subprocess\n",
    "import textwrap\n",
    "\n",
    "try:\n",
    "    import module\n",
    "except ImportError:\n",
    "    module = None\n",
    "    print(\"Python `module` helper is not available in this kernel. Continuing with PATH checks.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_nextflow_module = None\n",
    "\n",
    "if module is not None:\n",
    "    # Try a small set of common module names in Neurodesk images.\n",
    "    for candidate in [\"nextflow\", \"nextflow/24.10.4\", \"nextflow/24.04.4\", \"nextflow/23.10.1\"]:\n",
    "        try:\n",
    "            await module.load(candidate)\n",
    "            loaded_nextflow_module = candidate\n",
    "            print(f\"Loaded module: {candidate}\")\n",
    "            break\n",
    "        except Exception as exc:\n",
    "            print(f\"Could not load {candidate}: {exc}\")\n",
    "\n",
    "    await module.list()\n",
    "else:\n",
    "    print(\"Skipping module loading.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_and_print(cmd):\n",
    "    # Run a shell command without failing the notebook on non-zero exit.\n",
    "    print(\"$\", \" \".join(cmd))\n",
    "    proc = subprocess.run(cmd, text=True, capture_output=True)\n",
    "    if proc.stdout.strip():\n",
    "        print(proc.stdout.strip())\n",
    "    if proc.stderr.strip():\n",
    "        print(proc.stderr.strip())\n",
    "    print(f\"[exit code: {proc.returncode}]\")\n",
    "    return proc\n",
    "\n",
    "nextflow_ok = shutil.which(\"nextflow\") is not None\n",
    "datalad_ok = shutil.which(\"datalad\") is not None\n",
    "python_ok = shutil.which(\"python3\") is not None\n",
    "\n",
    "print(f\"nextflow in PATH: {nextflow_ok}\")\n",
    "print(f\"datalad in PATH: {datalad_ok}\")\n",
    "print(f\"python3 in PATH: {python_ok}\")\n",
    "\n",
    "if nextflow_ok:\n",
    "    run_and_print([\"nextflow\", \"-version\"])\n",
    "if datalad_ok:\n",
    "    run_and_print([\"datalad\", \"--version\"])\n",
    "\n",
    "nibabel_available = importlib.util.find_spec(\"nibabel\") is not None\n",
    "print(f\"nibabel available in notebook kernel: {nibabel_available}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write a DSL2 pipeline\n",
    "\n",
    "The cell below writes a complete Nextflow script to disk.\n",
    "\n",
    "Important points to notice:\n",
    "- `Channel.fromPath(...)` searches for candidate T1w files.\n",
    "- A BIDS-aware regex keeps only `sub-*/(ses-*/)?anat/*_T1w` paths.\n",
    "- `T1wQcPerSubject` runs once per input image.\n",
    "- `MergeQc` concatenates all per-subject QC files into one summary table.\n",
    "\n",
    "This is the same logic pattern you provided, with defaults that point to a local demo directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = Path.cwd() / \"nextflow_neuro_demo\"\n",
    "PIPELINE = ROOT_DIR / \"example_neuroimaging_qc.nf\"\n",
    "LOCAL_BIDS = ROOT_DIR / \"example_bids\"\n",
    "LOCAL_OUT = ROOT_DIR / \"example_qc_results\"\n",
    "\n",
    "ROOT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "pipeline_text = textwrap.dedent(r\"\"\"#!/usr/bin/env nextflow\n",
    "\n",
    "nextflow.enable.dsl = 2\n",
    "\n",
    "params.bids = params.bids ?: \"${projectDir}/example_bids\"\n",
    "params.outdir = params.outdir ?: \"${projectDir}/example_qc_results\"\n",
    "\n",
    "/*\n",
    "Example:\n",
    "  nextflow run example_neuroimaging_qc.nf \\\n",
    "    --bids /path/to/bids_dataset \\\n",
    "    --outdir /path/to/output\n",
    "*/\n",
    "\n",
    "def t1wPatterns = [\n",
    "    \"${params.bids}/**/*_T1w.nii.gz\",\n",
    "    \"${params.bids}/**/*_T1w.nii\"\n",
    "]\n",
    "\n",
    "Channel\n",
    "    .fromPath(t1wPatterns, type: \"any\", followLinks: true)\n",
    "    .filter { t1w ->\n",
    "        def path = t1w.toString()\n",
    "        path ==~ /.*\\/sub-[^\\/]+\\/(ses-[^\\/]+\\/)?anat\\/.*_T1w\\.nii(\\.gz)?$/ && t1w.exists()\n",
    "    }\n",
    "    .ifEmpty {\n",
    "        error \"No readable T1w files found in BIDS anat folders under ${params.bids}. If this is an OpenNeuro/DataLad clone, run datalad get on *_T1w.nii.gz files first.\"\n",
    "    }\n",
    "    .map { t1w ->\n",
    "        def matcher = (t1w.baseName =~ /(sub-[^_]+(?:_ses-[^_]+)?)/)\n",
    "        def id = matcher ? matcher[0][1] : t1w.baseName\n",
    "        tuple(id, t1w)\n",
    "    }\n",
    "    .set { t1w_files }\n",
    "\n",
    "process T1wQcPerSubject {\n",
    "    tag \"${id}\"\n",
    "    publishDir \"${params.outdir}/per_subject\", mode: \"copy\"\n",
    "\n",
    "    input:\n",
    "    tuple val(id), path(t1w)\n",
    "\n",
    "    output:\n",
    "    path \"${id}.qc.tsv\"\n",
    "\n",
    "    script:\n",
    "    \"\"\"\n",
    "    python3 - << 'PY'\n",
    "import nibabel as nib\n",
    "from pathlib import Path\n",
    "\n",
    "subject = \"${id}\"\n",
    "t1w = Path(\"${t1w}\")\n",
    "img = nib.load(str(t1w))\n",
    "shape = \"x\".join(str(v) for v in img.shape)\n",
    "zooms = \"x\".join(f\"{z:.3f}\" for z in img.header.get_zooms()[:3])\n",
    "\n",
    "with open(f\"{subject}.qc.tsv\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"id\\tfile\\tshape\\tvoxel_size_mm\\n\")\n",
    "    f.write(f\"{subject}\\t{t1w.name}\\t{shape}\\t{zooms}\\n\")\n",
    "PY\n",
    "    \"\"\"\n",
    "}\n",
    "\n",
    "process MergeQc {\n",
    "    publishDir \"${params.outdir}\", mode: \"copy\"\n",
    "\n",
    "    input:\n",
    "    path qc_tables\n",
    "\n",
    "    output:\n",
    "    path \"t1w_qc_summary.tsv\"\n",
    "\n",
    "    script:\n",
    "    \"\"\"\n",
    "    set -euo pipefail\n",
    "    first=$(ls *.qc.tsv | head -n 1)\n",
    "    head -n 1 \"$first\" > t1w_qc_summary.tsv\n",
    "    tail -n +2 -q *.qc.tsv >> t1w_qc_summary.tsv\n",
    "    \"\"\"\n",
    "}\n",
    "\n",
    "workflow {\n",
    "    T1wQcPerSubject(t1w_files)\n",
    "    MergeQc(T1wQcPerSubject.out.collect())\n",
    "}\n",
    "\"\"\")\n",
    "\n",
    "PIPELINE.write_text(pipeline_text, encoding=\"utf-8\")\n",
    "\n",
    "print(f\"Pipeline written to: {PIPELINE}\")\n",
    "print(f\"Default BIDS dir:    {LOCAL_BIDS}\")\n",
    "print(f\"Default output dir:  {LOCAL_OUT}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick preview of the generated Nextflow script\n",
    "print(\"\\n\".join(PIPELINE.read_text(encoding=\"utf-8\").splitlines()[:60]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a tiny local BIDS dataset\n",
    "\n",
    "This section avoids external downloads and gives you a deterministic test case.\n",
    "\n",
    "If `nibabel` is present, we generate two fake T1w images:\n",
    "- `sub-01/anat/sub-01_T1w.nii.gz`\n",
    "- `sub-02/anat/sub-02_T1w.nii.gz`\n",
    "\n",
    "These are sufficient to validate Nextflow channel selection and process fan-out.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not nibabel_available:\n",
    "    print(\"nibabel is missing in this kernel. Skipping synthetic dataset creation.\")\n",
    "else:\n",
    "    import json\n",
    "    import numpy as np\n",
    "    import nibabel as nib\n",
    "\n",
    "    LOCAL_BIDS.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    dataset_description = {\n",
    "        \"Name\": \"Synthetic Nextflow Neurodesk Demo\",\n",
    "        \"BIDSVersion\": \"1.8.0\",\n",
    "    }\n",
    "    (LOCAL_BIDS / \"dataset_description.json\").write_text(\n",
    "        json.dumps(dataset_description, indent=2) + \"\\n\",\n",
    "        encoding=\"utf-8\",\n",
    "    )\n",
    "\n",
    "    rng = np.random.default_rng(seed=42)\n",
    "    for subject in [\"sub-01\", \"sub-02\"]:\n",
    "        anat_dir = LOCAL_BIDS / subject / \"anat\"\n",
    "        anat_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        data = (rng.random((32, 32, 24), dtype=np.float32) * 1000.0).astype(\"float32\")\n",
    "        affine = np.array([\n",
    "            [1.0, 0.0, 0.0, 0.0],\n",
    "            [0.0, 1.0, 0.0, 0.0],\n",
    "            [0.0, 0.0, 1.2, 0.0],\n",
    "            [0.0, 0.0, 0.0, 1.0],\n",
    "        ])\n",
    "        img = nib.Nifti1Image(data, affine)\n",
    "        out_file = anat_dir / f\"{subject}_T1w.nii.gz\"\n",
    "        nib.save(img, out_file)\n",
    "        print(f\"Wrote {out_file}\")\n",
    "\n",
    "    print(\"\\nSynthetic BIDS dataset is ready.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Nextflow and inspect outputs\n",
    "\n",
    "We run the pipeline against the local synthetic dataset.\n",
    "\n",
    "The notebook does not crash on command failures: this keeps documentation readable even when users are missing tools in a custom environment. In a real project, you would usually enforce `check=True` and fail fast.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_and_print_tail(cmd, tail_lines=40):\n",
    "    print(\"$\", \" \".join(cmd))\n",
    "    proc = subprocess.run(cmd, text=True, capture_output=True)\n",
    "\n",
    "    stdout_lines = proc.stdout.strip().splitlines()\n",
    "    stderr_lines = proc.stderr.strip().splitlines()\n",
    "\n",
    "    if stdout_lines:\n",
    "        print(\"--- stdout (tail) ---\")\n",
    "        print(\"\\n\".join(stdout_lines[-tail_lines:]))\n",
    "    if stderr_lines:\n",
    "        print(\"--- stderr (tail) ---\")\n",
    "        print(\"\\n\".join(stderr_lines[-tail_lines:]))\n",
    "\n",
    "    print(f\"[exit code: {proc.returncode}]\")\n",
    "    return proc\n",
    "\n",
    "can_run_local_demo = nextflow_ok and python_ok and nibabel_available and (LOCAL_BIDS / \"dataset_description.json\").exists()\n",
    "\n",
    "if can_run_local_demo:\n",
    "    LOCAL_OUT.mkdir(parents=True, exist_ok=True)\n",
    "    run_and_print_tail([\n",
    "        \"nextflow\",\n",
    "        \"run\",\n",
    "        str(PIPELINE),\n",
    "        \"--bids\",\n",
    "        str(LOCAL_BIDS),\n",
    "        \"--outdir\",\n",
    "        str(LOCAL_OUT),\n",
    "    ])\n",
    "else:\n",
    "    print(\"Skipping local Nextflow run. Missing one or more prerequisites:\")\n",
    "    print(f\"  nextflow_ok={nextflow_ok}\")\n",
    "    print(f\"  python_ok={python_ok}\")\n",
    "    print(f\"  nibabel_available={nibabel_available}\")\n",
    "    print(f\"  dataset_exists={(LOCAL_BIDS / 'dataset_description.json').exists()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_path = LOCAL_OUT / \"t1w_qc_summary.tsv\"\n",
    "\n",
    "if summary_path.exists():\n",
    "    print(f\"QC summary found at: {summary_path}\")\n",
    "    print()\n",
    "    print(summary_path.read_text(encoding=\"utf-8\"))\n",
    "else:\n",
    "    print(\"QC summary file not found yet. If needed, inspect Nextflow logs above.\")\n",
    "\n",
    "per_subject_dir = LOCAL_OUT / \"per_subject\"\n",
    "if per_subject_dir.exists():\n",
    "    print(\"Per-subject files:\")\n",
    "    for p in sorted(per_subject_dir.glob(\"*.qc.tsv\")):\n",
    "        print(\" -\", p.name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: OpenNeuro + DataLad helper script\n",
    "\n",
    "The next cell writes a helper shell script based on your requested pattern.\n",
    "\n",
    "It does the following:\n",
    "- clones an OpenNeuro dataset with DataLad,\n",
    "- downloads a limited number of T1w files,\n",
    "- runs the same Nextflow pipeline,\n",
    "- prints the merged QC summary.\n",
    "\n",
    "By default we only *write* this script (no large network operations during notebook execution).\n",
    "\n",
    "To run it, set:\n",
    "- `RUN_OPENNEURO_DEMO=1`\n",
    "- optional `OPENNEURO_DATASET_ID` (default `ds000030`)\n",
    "- optional `OPENNEURO_MAX_T1W` (default `2`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_SCRIPT = ROOT_DIR / \"run_openneuro_nextflow_demo.sh\"\n",
    "\n",
    "run_script_text = textwrap.dedent(r\"\"\"#!/usr/bin/env bash\n",
    "set -euo pipefail\n",
    "\n",
    "ROOT_DIR=\"${1:-$PWD/nextflow_neuro_demo}\"\n",
    "DATASET_ID=\"${2:-${OPENNEURO_DATASET_ID:-ds000030}}\"\n",
    "MAX_T1W=\"${3:-${OPENNEURO_MAX_T1W:-2}}\"\n",
    "\n",
    "mkdir -p \"${ROOT_DIR}\"\n",
    "PIPELINE=\"${ROOT_DIR}/example_neuroimaging_qc.nf\"\n",
    "BIDS_DIR=\"${ROOT_DIR}/${DATASET_ID}\"\n",
    "OUT_DIR=\"${ROOT_DIR}/example_qc_results\"\n",
    "\n",
    "require_cmd() {\n",
    "    local cmd=\"$1\"\n",
    "    if ! command -v \"${cmd}\" >/dev/null 2>&1; then\n",
    "        echo \"Missing required command: ${cmd}\" >&2\n",
    "        exit 1\n",
    "    fi\n",
    "}\n",
    "\n",
    "require_cmd datalad\n",
    "require_cmd nextflow\n",
    "\n",
    "if [ ! -f \"${PIPELINE}\" ]; then\n",
    "    if [ -f /opt/neurodesktop/example_neuroimaging_qc.nf ]; then\n",
    "        cp -f /opt/neurodesktop/example_neuroimaging_qc.nf \"${PIPELINE}\"\n",
    "    elif [ -f \"$(dirname \"$0\")/example_neuroimaging_qc.nf\" ]; then\n",
    "        cp -f \"$(dirname \"$0\")/example_neuroimaging_qc.nf\" \"${PIPELINE}\"\n",
    "    else\n",
    "        echo \"Could not find example_neuroimaging_qc.nf. Write it first from the notebook cell.\" >&2\n",
    "        exit 1\n",
    "    fi\n",
    "fi\n",
    "\n",
    "if [ ! -d \"${BIDS_DIR}/.datalad\" ]; then\n",
    "    echo \"Cloning OpenNeuro dataset ${DATASET_ID} with DataLad...\"\n",
    "    datalad clone \"///openneuro/${DATASET_ID}\" \"${BIDS_DIR}\"\n",
    "else\n",
    "    echo \"Using existing dataset clone at ${BIDS_DIR}\"\n",
    "fi\n",
    "\n",
    "cd \"${BIDS_DIR}\"\n",
    "echo \"Installing OpenNeuro subdataset metadata (no file content yet)...\"\n",
    "datalad get -n -r .\n",
    "\n",
    "mapfile -t t1w_candidates < <(\n",
    "    find . \\( -type f -o -type l \\)         \\( -path \"./sub-*/anat/*_T1w.nii.gz\" -o -path \"./sub-*/ses-*/anat/*_T1w.nii.gz\" \\)         | sort\n",
    ")\n",
    "\n",
    "if [ \"${#t1w_candidates[@]}\" -eq 0 ]; then\n",
    "    echo \"No T1w files found in ${DATASET_ID}. Try another OpenNeuro dataset via OPENNEURO_DATASET_ID.\" >&2\n",
    "    exit 1\n",
    "fi\n",
    "\n",
    "if ! [[ \"${MAX_T1W}\" =~ ^[0-9]+$ ]] || [ \"${MAX_T1W}\" -lt 1 ]; then\n",
    "    echo \"OPENNEURO_MAX_T1W must be an integer >= 1 (current: ${MAX_T1W})\" >&2\n",
    "    exit 1\n",
    "fi\n",
    "\n",
    "selected_t1w=(\"${t1w_candidates[@]:0:${MAX_T1W}}\")\n",
    "get_targets=(\"dataset_description.json\")\n",
    "\n",
    "for rel in \"${selected_t1w[@]}\"; do\n",
    "    rel=\"${rel#./}\"\n",
    "    get_targets+=(\"${rel}\")\n",
    "    json=\"${rel%.nii.gz}.json\"\n",
    "    if [ -e \"${json}\" ] || [ -L \"${json}\" ]; then\n",
    "        get_targets+=(\"${json}\")\n",
    "    fi\n",
    "done\n",
    "\n",
    "echo \"Downloading ${#get_targets[@]} file(s) from OpenNeuro dataset ${DATASET_ID}...\"\n",
    "datalad get \"${get_targets[@]}\"\n",
    "\n",
    "echo \"Running Nextflow QC pipeline...\"\n",
    "nextflow run \"${PIPELINE}\" --bids \"${BIDS_DIR}\" --outdir \"${OUT_DIR}\"\n",
    "\n",
    "echo\n",
    "echo \"Done. QC summary:\"\n",
    "cat \"${OUT_DIR}/t1w_qc_summary.tsv\"\n",
    "\"\"\")\n",
    "\n",
    "RUN_SCRIPT.write_text(run_script_text, encoding=\"utf-8\")\n",
    "RUN_SCRIPT.chmod(0o755)\n",
    "\n",
    "print(f\"Helper script written: {RUN_SCRIPT}\")\n",
    "print(\"Use it manually, for example:\")\n",
    "print(f\"  bash {RUN_SCRIPT} {ROOT_DIR/'openneuro_demo'} ds000030 2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_openneuro_demo = os.environ.get(\"RUN_OPENNEURO_DEMO\", \"0\") == \"1\"\n",
    "\n",
    "if run_openneuro_demo:\n",
    "    if not nextflow_ok or not datalad_ok:\n",
    "        print(\"Cannot run OpenNeuro demo because nextflow or datalad is missing.\")\n",
    "    else:\n",
    "        openneuro_root = ROOT_DIR / \"openneuro_demo\"\n",
    "        dataset_id = os.environ.get(\"OPENNEURO_DATASET_ID\", \"ds000030\")\n",
    "        max_t1w = os.environ.get(\"OPENNEURO_MAX_T1W\", \"2\")\n",
    "\n",
    "        run_and_print_tail([\n",
    "            \"bash\",\n",
    "            str(RUN_SCRIPT),\n",
    "            str(openneuro_root),\n",
    "            dataset_id,\n",
    "            max_t1w,\n",
    "        ], tail_lines=80)\n",
    "else:\n",
    "    print(\"OpenNeuro/DataLad run skipped (set RUN_OPENNEURO_DEMO=1 to enable).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpreting and extending this pipeline\n",
    "\n",
    "Ways to adapt this pattern in your own Neurodesk projects:\n",
    "- Add more BIDS modalities (e.g., T2w, bold) by extending `t1wPatterns` or making separate channels.\n",
    "- Replace the QC code block with your real per-subject analysis (FSL/AFNI/ANTs/SPM commands).\n",
    "- Add process-level resources (`cpus`, `memory`, `time`) and executor config for HPC.\n",
    "- Track provenance by storing pipeline files and run scripts with your dataset repository.\n",
    "\n",
    "For bigger projects, split configuration into `nextflow.config` and keep `.nf` scripts focused on workflow logic.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies and environment capture\n",
    "\n",
    "As in the Neurodesk notebook template, we capture environment details at the end. If `watermark` is unavailable, the notebook continues and prints a message.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    %load_ext watermark\n",
    "    %watermark\n",
    "    %watermark --iversions\n",
    "except Exception as exc:\n",
    "    print(\"Could not run watermark extension:\", exc)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "rise": {
   "scroll": true,
   "start_slideshow_at": "selected"
  },
  "nd_review_id": "c3fb5643-2183-4867-95d5-998715f8b247"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
